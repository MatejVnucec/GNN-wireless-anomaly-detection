{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71e8e40-5bd1-4cdc-ac0e-0ac3088277ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59a55-999c-48f2-822b-92535186360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install pytorch=1.12 torchvision torchaudio cudatoolkit=11.3 -c pytorch -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82c180-a189-4cb9-8375-690bfd8d522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
      "Collecting torch-scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.1.0%2Bpt112cu113-cp39-cp39-linux_x86_64.whl (8.9 MB)\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.0+pt112cu113\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
      "Collecting torch-sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15%2Bpt112cu113-cp39-cp39-linux_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from torch-sparse) (1.7.2)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from scipy->torch-sparse) (1.20.3)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.15+pt112cu113\n",
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.1.0.post1-py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (1.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (4.62.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (1.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (1.7.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->torch-geometric) (2.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.1.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu113.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209013ec-4327-45ed-9038-815a6e93cb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!mamba install -c conda-forge pyts -q -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f794a100-20d7-4bfc-bd15-a9e6c680bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llvmpy\n",
      "  Using cached llvmpy-0.12.7.tar.gz (657 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_1cc141d8a23f4810ab097dd42e590db9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_1cc141d8a23f4810ab097dd42e590db9/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-rcld9iig\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_1cc141d8a23f4810ab097dd42e590db9/\n",
      "  Complete output (2 lines):\n",
      "  Error: could not invoke ['llvm-config', '--version']\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/97/0f/98b78dc8a5ec032e05179fc406622e550d5c571f036beca8f06a4752f648/llvmpy-0.12.7.tar.gz#sha256=2f0f37aa7966d267a9ababe59f7f3c861a5b7b928205c9137275f7032f4132c7 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.12.6.tar.gz (654 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_5052a35973e44987975682e78bf363cf/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_5052a35973e44987975682e78bf363cf/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-cnvn504u\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_5052a35973e44987975682e78bf363cf/\n",
      "  Complete output (2 lines):\n",
      "  Error: could not invoke ['llvm-config', '--version']\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/61/97/ad6be5dd5c7753fc1839433a3b6944ca6305b9f50a19f6462c0703c30e38/llvmpy-0.12.6.tar.gz#sha256=a468a4b2c3c969fa33a5151c6f99acc31dcbce6cd32c13a7b029096101f47de8 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.12.5.tar.gz (659 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_24f7d839c49f4026a65144b07450c231/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_24f7d839c49f4026a65144b07450c231/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-r7iigqz5\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_24f7d839c49f4026a65144b07450c231/\n",
      "  Complete output (2 lines):\n",
      "  Error: could not invoke ['llvm-config', '--version']\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/79/9e/4096e02a789d1beb719f9a0be476907bc9508a0e2b463e32694dbbced422/llvmpy-0.12.5.tar.gz#sha256=b544fc1cad3f7b7e6e40482b00405dffb7c0dbd60adc03fb395dfb8d5b3785a2 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.12.4.tar.gz (651 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_2400889482a644098655114bc8c82da4/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_2400889482a644098655114bc8c82da4/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-x5qyyp9t\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_2400889482a644098655114bc8c82da4/\n",
      "  Complete output (5 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-install-njbhsx6n/llvmpy_2400889482a644098655114bc8c82da4/setup.py\", line 7, in <module>\n",
      "      import versioneer\n",
      "  ModuleNotFoundError: No module named 'versioneer'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ad/06/5746eb3fe8b1d487dd7ade959fc43d61d9a9eadfabc80ec2ecae80252727/llvmpy-0.12.4.tar.gz#sha256=399ab16f613fb9f742e8338701c2e1c605817b2aab36cc2b202e0b681ef7561c (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.11.2.tar.gz (642 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_da608a2e402447c88abc97f06df00675/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_da608a2e402447c88abc97f06df00675/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-u82p8u_i\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_da608a2e402447c88abc97f06df00675/\n",
      "  Complete output (2 lines):\n",
      "  Error: could not invoke ['llvm-config', '--version']\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/88/99/1f75d3b46f4f732b70c7ece77d0143036d29683e39eb09a383297055a7a0/llvmpy-0.11.2.tar.gz#sha256=c7911b743d4d3ac746eca6d0c0809963fc326bdc079a27fb2e3053e0474fa299 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.11.0.tar.gz (637 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_b73fffdc19484ef698d695bd763365ea/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_b73fffdc19484ef698d695bd763365ea/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-suc7vo_l\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_b73fffdc19484ef698d695bd763365ea/\n",
      "  Complete output (2 lines):\n",
      "  Error: could not invoke ['llvm-config', '--version']\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/96/68/510e540e6d63753c56191654cd26a002cd2b215cd7e5e5e81a7b4cb1e3cd/llvmpy-0.11.0.tar.gz#sha256=59165fbf2e3aae5642c3b7abe56296bf1b90607ab2fa2192d16f7478f8cc7760 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.10.2.tar.gz (555 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_3544505bb44a4535a167c936d0a8d3f9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_3544505bb44a4535a167c936d0a8d3f9/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-2680zzfi\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_3544505bb44a4535a167c936d0a8d3f9/\n",
      "  Complete output (3 lines):\n",
      "  /bin/sh: 1: llvm-config: not found\n",
      "  Cannot invoke llvm-config.\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/35/bc/46b99038319e7ea3a0240e5f06ba609f8d195899a1fe442840fff9117027/llvmpy-0.10.2.tar.gz#sha256=bf48203483e8f521ed8181770bf41d031faf3ff2c168f9716d35e178f3991c7a (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.10.1.tar.gz (546 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_117dc4d0f9d643119ff8deecf9c048fe/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_117dc4d0f9d643119ff8deecf9c048fe/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-sbc1mt76\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_117dc4d0f9d643119ff8deecf9c048fe/\n",
      "  Complete output (3 lines):\n",
      "  /bin/sh: 1: llvm-config: not found\n",
      "  Cannot invoke llvm-config.\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/6e/70/bcc156a448def3e7f40f22dff7df175591a4b56a192258a71c02424e70fb/llvmpy-0.10.1.tar.gz#sha256=2225fca4080dd43b88143db75f52a5a02af26269138ff467844740187cce0c4e (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.10.0.tar.gz (540 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_48cff30853b44a9dbb09e0d173bc8759/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_48cff30853b44a9dbb09e0d173bc8759/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-nkq0_tgs\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_48cff30853b44a9dbb09e0d173bc8759/\n",
      "  Complete output (3 lines):\n",
      "  /bin/sh: 1: llvm-config: not found\n",
      "  Cannot invoke llvm-config.\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/94/3c/8563b6f88d225f530ad1cd21820c448df15e621fdf66e5b585ca09365009/llvmpy-0.10.0.tar.gz#sha256=13699df4b4ce8b0ad34762cc568e651471af22cd1e002d8e47d3a127855c7f25 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.9.tar.gz (414 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_a0ca879d66eb46558baeaaef7237d328/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_a0ca879d66eb46558baeaaef7237d328/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-zwqju7fg\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_a0ca879d66eb46558baeaaef7237d328/\n",
      "  Complete output (3 lines):\n",
      "  /bin/sh: 1: llvm-config: not found\n",
      "  Cannot invoke llvm-config.\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2d/14/5c151ed4ca7d9c7e823b280a02f20775516a177973fc855b03bb6ffb31de/llvmpy-0.9.tar.gz#sha256=f77741344879b7801922e5b85c1b83bc19b08fb1276466267d37253f4c9a4673 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Using cached llvmpy-0.8.2.tar.gz (486 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.9 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_ed56b711deff48feaffd93c80026b2a4/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-njbhsx6n/llvmpy_ed56b711deff48feaffd93c80026b2a4/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-kn0c0v1x\n",
      "       cwd: /tmp/pip-install-njbhsx6n/llvmpy_ed56b711deff48feaffd93c80026b2a4/\n",
      "  Complete output (3 lines):\n",
      "  /bin/sh: 1: llvm-config: not found\n",
      "  Cannot invoke llvm-config.\n",
      "  Try setting LLVM_CONFIG_PATH=/path/to/llvm-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/40/f6/9b1c48a88089980ac8e14f50cb53a94813dbb1deb5858f8d64b2a15e6a2c/llvmpy-0.8.2.tar.gz#sha256=0ed4a86e760f94a9ccfc3dab5565161c61fa50e8c457842030e1787b26b7d758 (from https://pypi.org/simple/llvmpy/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement llvmpy (from versions: 0.12.7-9-g60b512d, 0.8.2, 0.9, 0.10.0, 0.10.1, 0.10.2, 0.11.0, 0.11.2, 0.12.4, 0.12.5, 0.12.6, 0.12.7)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for llvmpy\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.9/site-packages (0.29.24)\n",
      "Requirement already satisfied: numba in /home/jovyan/.local/lib/python3.9/site-packages (0.56.2)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /opt/conda/lib/python3.9/site-packages (from numba) (1.20.3)\n",
      "Requirement already satisfied: setuptools<60 in /opt/conda/lib/python3.9/site-packages (from numba) (59.1.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/jovyan/.local/lib/python3.9/site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (2.6.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting ts2vg\n",
      "  Using cached ts2vg-1.0.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from ts2vg) (1.20.3)\n",
      "Installing collected packages: ts2vg\n",
      "Successfully installed ts2vg-1.0.0\n",
      "Collecting pytorch_lightning\n",
      "  Using cached pytorch_lightning-1.8.3.post1-py3-none-any.whl (798 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (4.62.3)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (2021.11.0)\n",
      "Collecting tensorboardX>=2.2\n",
      "  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (1.12.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (21.2)\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Using cached torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.9/site-packages (from pytorch_lightning) (6.0)\n",
      "Collecting lightning-utilities==0.3.*\n",
      "  Using cached lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting fire\n",
      "  Using cached fire-0.4.0-py2.py3-none-any.whl\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.26.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=17.0->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /opt/conda/lib/python3.9/site-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Collecting termcolor\n",
      "  Using cached termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.1)\n",
      "Installing collected packages: multidict, frozenlist, yarl, typing-extensions, termcolor, async-timeout, aiosignal, fire, aiohttp, torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 fire-0.4.0 frozenlist-1.3.3 lightning-utilities-0.3.0 multidict-6.0.2 pytorch-lightning-1.8.3.post1 tensorboardX-2.5.1 termcolor-2.1.1 torchmetrics-0.10.3 typing-extensions-4.4.0 yarl-1.8.1\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.50.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.1.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (59.1.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (21.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.1)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, requests-oauthlib, MarkupSafe, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.11.23 gast-0.4.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 keras-2.11.0 libclang-14.0.6 markdown-3.4.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 werkzeug-2.2.2 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llvmpy\n",
    "!pip install cython\n",
    "!pip install numba\n",
    "!pip install pandas\n",
    "!pip install networkx\n",
    "!pip install matplotlib\n",
    "!pip install ts2vg\n",
    "!pip install pytorch_lightning\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64d07e-430e-43fd-8fd7-11a12531e4b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca3d551-0aab-49a3-8fb9-2b5632323daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 13:20:07.919384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 13:20:08.539025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 13:20:08.539126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 13:20:08.539133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import sklearn\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import ts2vg\n",
    "import pytorch_lightning as pl\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from pyts.image import MarkovTransitionField\n",
    "\n",
    "from torch.nn import Linear, CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool, ChebConv, global_sort_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv, GINEConv, GATv2Conv, GATConv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import LearningRateFinder\n",
    "from pytorch_lightning.callbacks import BatchSizeFinder\n",
    "from pytorch_lightning.callbacks import ProgressBarBase\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from ts2vg import NaturalVG\n",
    "from ts2vg import HorizontalVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429b1b52-626e-4eb9-886a-e6f050c23778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all in one\n",
    "def create_graph():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # preparation for un/cut graphs\n",
    "    if len_type == \"un/cut\":\n",
    "    \n",
    "        df = pd.read_csv(path_main)  \n",
    "        del df['Unnamed: 0']\n",
    "        df.index, df.columns = [range(df.index.size), range(df.columns.size)]\n",
    "        length_rss = int((df.columns.stop-2)/2)\n",
    "        \n",
    "        X = df.loc[:,df.columns[:length_rss]].to_numpy()\n",
    "        Y = df[length_rss+1].to_numpy(dtype=np.uint8)\n",
    "        X_mask = df.loc[:,df.columns[length_rss+2:]].to_numpy()\n",
    "        \n",
    "        if graph_type in (\"MTF\", \"visual_on_MTF\", \"MTF_on_visual\"):\n",
    "            MTF = MarkovTransitionField(n_bins=length_rss)\n",
    "            X_gaf = MTF.fit_transform(X)\n",
    "        \n",
    "        \n",
    "    # preparation for random graphs\n",
    "    elif len_type == \"random\":\n",
    "        dataset_rss = np.load(path_main, allow_pickle=True)['arr_0']\n",
    "        dataset_properties = np.load(path_properties, allow_pickle=True)['arr_0']\n",
    "        dataset_mask = np.load(path_mask, allow_pickle=True)['arr_0']\n",
    "\n",
    "        for i in range(len(dataset_properties)):\n",
    "            dataset_properties[i,1] = int(dataset_properties[i,1])\n",
    "        \n",
    "        X = dataset_rss\n",
    "        X_mask = dataset_mask\n",
    "        Y = dataset_properties[:,2]\n",
    "        Y_len = dataset_properties[:,0]\n",
    "        if graph_type in (\"MTF\", \"visual_on_MTF\", \"MTF_on_visual\"):\n",
    "            X_gaf = []\n",
    "            for i in range(len(Y_len)):\n",
    "                MTF = MarkovTransitionField(n_bins=Y_len[i])\n",
    "                X_gaf_temp = MTF.fit_transform(X[i].reshape(1, -1))\n",
    "                X_gaf.append(X_gaf_temp[0])\n",
    "    \n",
    "    # output will have all graphs \n",
    "    output = []\n",
    "    \n",
    "    # setting class_weights for graph\n",
    "    global class_weights\n",
    "    weight_param = Y\n",
    "    if classif == \"graph\" and len_type == \"un/cut\":\n",
    "        weight_param = Y\n",
    "    class_weights = torch.tensor(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                                   classes=np.unique(weight_param),\n",
    "                                                                   y=weight_param))\n",
    "    \n",
    "    # function for creating edge index and edge weight for a given MTF matrix\n",
    "    def adjToEdgidx_MTF(adj_mat):\n",
    "        edge_index = torch.from_numpy(adj_mat).nonzero().t().contiguous()\n",
    "        row, col = edge_index\n",
    "        edge_weight = adj_mat[row, col]#adj_mat[row, col]\n",
    "        return edge_index, edge_weight\n",
    "    \n",
    "    def adjToEdgidx_visual(X_current):\n",
    "        g = NaturalVG(weighted='distance')\n",
    "        # g = HorizontalVG(weighted='distance')\n",
    "        g.build(X_current)\n",
    "\n",
    "        adj_mat_visual = np.zeros([len(X_current),len(X_current)], dtype='float')\n",
    "        for i in range(len(g.edges)):\n",
    "            x, y, q =g.edges[i]\n",
    "            adj_mat_visual[x,y] = q\n",
    "            adj_mat_visual[y,x] = q\n",
    "        \n",
    "        edge_index = torch.from_numpy(adj_mat_visual).nonzero().t().contiguous()\n",
    "        row, col = edge_index\n",
    "        edge_weight = adj_mat_visual[row, col]\n",
    "        \n",
    "        return edge_index, edge_weight\n",
    "    \n",
    "    def adjToEdgidx_join(adj_mat_MTF,X_current):\n",
    "        g = NaturalVG(weighted='distance')\n",
    "        #g = HorizontalVG(weighted='distance')\n",
    "        g.build(X_current)\n",
    "        \n",
    "        #create matrix for visual\n",
    "        adj_mat_visual = np.zeros([len(adj_mat_MTF),len(adj_mat_MTF)], dtype='float')\n",
    "        for i in range(len(g.edges)):\n",
    "            x, y, q =g.edges[i]\n",
    "            adj_mat_visual[x,y] = q\n",
    "            adj_mat_visual[y,x] = q\n",
    "            \n",
    "        if graph_type == \"visual_on_MTF\":\n",
    "            temp_main_adj_mat = adj_mat_MTF\n",
    "        elif graph_type == \"MTF_on_visual\":\n",
    "            temp_main_adj_mat = adj_mat_visual\n",
    "            \n",
    "        edge_index = torch.from_numpy(temp_main_adj_mat).nonzero().t().contiguous()\n",
    "        \n",
    "        #join two edge_weight arrays (visual is converted to fit MTF) \n",
    "        row, col = edge_index\n",
    "        edge_weight = np.zeros([len(row),2], dtype='float')\n",
    "        edge_weight[:,0] = adj_mat_MTF[row, col]\n",
    "        edge_weight[:,1] = adj_mat_visual[row, col]\n",
    "        \n",
    "        return edge_index, edge_weight\n",
    "    \n",
    "    def define_mask(i):\n",
    "        if classif == \"graph\": # for graph classification\n",
    "            return torch.tensor(Y[i], dtype=torch.long)      \n",
    "        elif classif == \"node\":# for node classification \n",
    "            return torch.unsqueeze(torch.tensor(X_mask[i], dtype=torch.double),1)\n",
    "        \n",
    "    if graph_type == \"MTF\":  \n",
    "        for i, j in enumerate(X_gaf):\n",
    "            edge_index, edge_weight = adjToEdgidx_MTF(j)\n",
    "            y_mask = define_mask(i)\n",
    "            #Into Data save node values \"x\", edge index from adjacency matrix and edge features/attributes, finally label\n",
    "            output.append(Data(x=torch.unsqueeze(torch.tensor(X[i], dtype=torch.double),1), edge_index=edge_index, edge_attr=torch.unsqueeze(torch.tensor(edge_weight, dtype=torch.double),1), y=y_mask))\n",
    "    elif graph_type == \"visual\":\n",
    "        for i in range(len(X)):\n",
    "            edge_index, edge_weight = adjToEdgidx_visual(X[i])\n",
    "            y_mask = define_mask(i)\n",
    "            output.append(Data(x=torch.unsqueeze(torch.tensor(X[i], dtype=torch.double),1), edge_index=torch.tensor(edge_index, dtype=torch.int64), edge_attr=torch.unsqueeze(torch.tensor(edge_weight, dtype=torch.double),1),y=y_mask))    \n",
    "    elif graph_type in (\"visual_on_MTF\", \"MTF_on_visual\"):\n",
    "        for i, j in enumerate(X_gaf):\n",
    "            edge_index, edge_weight = adjToEdgidx_join(j, X[i])\n",
    "            y_mask = define_mask(i) \n",
    "            output.append(Data(x=torch.unsqueeze(torch.tensor(X[i], dtype=torch.double),1), edge_index=edge_index, edge_attr=torch.tensor(edge_weight, dtype=torch.double), y=y_mask))    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22144ec-0e8b-4310-a0df-0a2d41af56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeps the last output so we dont have to generate another if all parameters are the same as before\n",
    "global temp_repeat\n",
    "temp_repeat=['']*6\n",
    "def generate_output():\n",
    "    if temp_repeat[0] != graph_type or temp_repeat[1] != classif or temp_repeat[2] != len_type or temp_repeat[3] != path_main or temp_repeat[4] != path_properties or temp_repeat[5] != path_mask:\n",
    "    \n",
    "        global output\n",
    "        output = create_graph()\n",
    "            \n",
    "    temp_repeat[0] = graph_type \n",
    "    temp_repeat[1] = classif\n",
    "    temp_repeat[2] = len_type\n",
    "    temp_repeat[3] = path_main\n",
    "    temp_repeat[4] = path_properties\n",
    "    temp_repeat[5] = path_mask\n",
    "    \n",
    "    print(temp_repeat[1] + \" classification on \" + temp_repeat[2] + \" time series using \" + temp_repeat[0] + \" graphs\" )\n",
    "    \n",
    "    return output\n",
    "\n",
    "def check_for_missclick():\n",
    "    return graph_type in (\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\") and classif in (\"graph\", \"node\") and len_type in (\"un/cut\", \"random\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37303612-ad33-4149-bb9c-f5c62aa27d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test_loop():\n",
    "    \n",
    "    import os, sys\n",
    "    versions = os.listdir(\"Models/\"+version)\n",
    "    len_ver = len(versions)\n",
    "    SEED_temp=SEED\n",
    "    for i in range(len_ver):\n",
    "        \n",
    "        global device, model\n",
    "            \n",
    "        torch.manual_seed(SEED_temp)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        output = generate_output()\n",
    "\n",
    "        train_size = int(0.8 * len(output))\n",
    "        Temp_size = len(output) - train_size\n",
    "        val_size = int(0.2*Temp_size)\n",
    "        test_size = Temp_size - val_size\n",
    "        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(output, [train_size, val_size, test_size])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        model = GINE.load_from_checkpoint(\"Models/\"+version+\"/version_\" + str(i) + \"/checkpoints/\" + monitor_test).double()\n",
    "        #model = Net.load_from_checkpoint(\"tb_logs/impact_of_TS_length_on_GNN_classification_performance/version_41/checkpoints/best.ckpt\").double()\n",
    "        trainer = pl.Trainer(accelerator='gpu',devices=1)\n",
    "        trainer.test(model, test_loader)\n",
    "        print(\"version_\"+str(i))\n",
    "        print(SEED_temp)\n",
    "        SEED_temp += 1\n",
    "\n",
    "class FineTuneLearningRateFinder(LearningRateFinder):\n",
    "    def __init__(self, milestones, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.milestones = milestones\n",
    "\n",
    "    def on_fit_start(self, *args, **kwargs):\n",
    "        return\n",
    "\n",
    "    def on_train_epoch_start(self, trainer, pl_module):\n",
    "        if trainer.current_epoch in self.milestones or trainer.current_epoch == 0:\n",
    "            self.lr_find(trainer, pl_module)\n",
    "\n",
    "# class for node classification            \n",
    "class GINE(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(GINE, self).__init__()\n",
    "        \n",
    "        if graph_type in (\"MTF\", \"visual\"):\n",
    "            edge_dim = 1\n",
    "        elif graph_type in (\"MTF_on_visual\", \"visual_on_MTF\"):\n",
    "            edge_dim = 2\n",
    "            \n",
    "        dim_h = 32\n",
    "    \n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv3 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv4 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        self.conv5 = GINEConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()), edge_dim=edge_dim)\n",
    "        \n",
    "        \n",
    "        self.lin1 = Linear(dim_h*5, dim_h*5)\n",
    "        self.lin2 = Linear(dim_h*5, 5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index, edge_attr=edge_weight)\n",
    "        h2 = self.conv2(h1, edge_index, edge_attr=edge_weight)\n",
    "        h3 = self.conv3(h2, edge_index, edge_attr=edge_weight)\n",
    "        h4 = self.conv4(h3, edge_index, edge_attr=edge_weight)\n",
    "        h5 = self.conv5(h4, edge_index, edge_attr=edge_weight)\n",
    "        \n",
    "        # Graph-level readout\n",
    "        \n",
    "        h1 = global_max_pool(h1, batch)\n",
    "        h2 = global_max_pool(h2, batch)\n",
    "        h3 = global_max_pool(h3, batch)\n",
    "        h4 = global_max_pool(h4, batch)\n",
    "        h5 = global_max_pool(h5, batch)\n",
    "        \n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3, h4, h5), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "                     \n",
    "        out = model(train_batch)\n",
    "        loss_function = CrossEntropyLoss(weight=class_weights).to(device) #weight=class_weights\n",
    "        train_loss = loss_function(out, train_batch.y)\n",
    "        \n",
    "        correct=out.argmax(dim=1).eq(train_batch.y).sum().item()\n",
    "        logs={\"train_loss\": train_loss}\n",
    "        total=len(train_batch.y)\n",
    "        \n",
    "        batch_dictionary={\"loss\": train_loss, \"log\": logs, \"correct\": correct, \"total\": total}\n",
    "        \n",
    "        return train_loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "      \n",
    "        out = model(val_batch)\n",
    "        loss_function = CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        val_loss = loss_function(out, val_batch.y)\n",
    "        \n",
    "        pred = out.argmax(-1)\n",
    "        correct=out.argmax(dim=1).eq(val_batch.y).sum().item()\n",
    "        total=len(val_batch.y)\n",
    "        val_label = val_batch.y\n",
    "        accuracy = (pred == val_label).sum() / pred.shape[0]\n",
    "        \n",
    "        logs={\"train_loss\": val_loss}\n",
    "        batch_dictionary={\"loss\": val_loss, \"log\": logs, \"correct\": correct, \"total\": total}\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", accuracy)\n",
    "        \n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        out = model(test_batch)\n",
    "        loss_function = CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        test_loss = loss_function(out, test_batch.y)\n",
    "        \n",
    "        pred = out.argmax(-1)\n",
    "        test_label = test_batch.y\n",
    "        accuracy = (pred == test_label).sum() / pred.shape[0]\n",
    "        self.log(\"test_true\", test_label)\n",
    "        self.log(\"test_pred\", pred)\n",
    "        self.log(\"test_acc\", accuracy)\n",
    "        return pred, test_label\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        #this function gives us in the outputs all acumulated pred and test_labels we returned in test_step\n",
    "        #we transform the pred and test_label into a shape that the classification report can read\n",
    "        true_array=[]\n",
    "        pred_array = []\n",
    "        for i in range(len(outputs)):\n",
    "            true_array = np.append(true_array,outputs[i][1].cpu().numpy())\n",
    "            pred_array = np.append(pred_array,outputs[i][0].cpu().numpy())            \n",
    "        print(confusion_matrix(true_array, pred_array))\n",
    "        print(classification_report(true_array, pred_array))\n",
    "        return pred_array, true_array\n",
    "    \n",
    "#---------------------------------------------------------------------------------\n",
    "# class for node classification\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = GATConv(1, 32, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(1, 4 * 32)\n",
    "        self.conv2 = GATConv(4 * 32, 32, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * 32, 4 * 32)\n",
    "        self.conv3 = GATConv(4 * 32, 1, heads=6,concat=False)\n",
    "        self.lin3 = torch.nn.Linear(4 * 32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):        \n",
    "        out = model(train_batch)\n",
    "        loss_function = BCEWithLogitsLoss().to(device) #weight=class_weights[1]\n",
    "        \n",
    "        train_loss = loss_function(out, train_batch.y)\n",
    "        correct=out.argmax(dim=1).eq(train_batch.y).sum().item()\n",
    "        logs={\"train_loss\": train_loss}\n",
    "        total=len(train_batch.y)\n",
    "        \n",
    "        batch_dictionary={\"loss\": train_loss, \"log\": logs, \"correct\": correct, \"total\": total}\n",
    "        \n",
    "        return train_loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "      \n",
    "        out = model(val_batch)\n",
    "        loss_function = BCEWithLogitsLoss().to(device)\n",
    "        val_loss = loss_function(out, val_batch.y)\n",
    "        \n",
    "        ys, preds = [], []\n",
    "        val_label = val_batch.y.cpu()\n",
    "        ys.append(val_batch.y)\n",
    "        preds.append((out > 0).float().cpu())     \n",
    "        y, pred = torch.cat(ys, dim=0), torch.cat(preds, dim=0)\n",
    "        accuracy = (pred == val_label).sum() / pred.shape[0]\n",
    "    \n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", accuracy)\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        out = model(test_batch)\n",
    "        loss_function = BCEWithLogitsLoss().to(device)\n",
    "        test_loss = loss_function(out, test_batch.y)\n",
    "        \n",
    "        ys, preds = [], []\n",
    "        test_label = test_batch.y.cpu()\n",
    "        ys.append(test_batch.y)\n",
    "        preds.append((out > 0).float().cpu())\n",
    "        \n",
    "        y, pred = torch.cat(ys, dim=0), torch.cat(preds, dim=0)\n",
    "        accuracy = (pred == test_label).sum() / pred.shape[0]\n",
    "        \n",
    "        self.log(\"test_acc\", accuracy)\n",
    "        return pred, y\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        #this function gives us in the outputs all acumulated pred and test_labels we returned in test_step\n",
    "        #we transform the pred and test_label into a shape that the classification report can read\n",
    "        true_array=[]\n",
    "        pred_array = []\n",
    "        for i in range(len(outputs)):\n",
    "            true_array = np.append(true_array,outputs[i][1].cpu().numpy())\n",
    "            pred_array = np.append(pred_array,outputs[i][0].cpu().numpy())   \n",
    "        print(confusion_matrix(true_array, pred_array))\n",
    "        print(classification_report(true_array, pred_array))\n",
    "        print(\"pred_array \",pred_array)\n",
    "\n",
    "        \n",
    "def main():\n",
    "    if check_for_missclick() != True:\n",
    "        print(\"one of the main parameters does not match\")\n",
    "    else:\n",
    "        global model, test_loader, device\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_acc',patience=patience, strict=False,verbose=False, mode='max')\n",
    "        val_checkpoint_acc = ModelCheckpoint(filename=\"max_acc-{epoch}-{step}-{val_acc:.3f}\", monitor = \"val_acc\", mode=\"max\")\n",
    "        val_checkpoint_best_loss = ModelCheckpoint(filename=\"best_loss\", monitor = \"val_loss\", mode=\"max\")\n",
    "        val_checkpoint_best_acc = ModelCheckpoint(filename=\"best_acc\", monitor = \"val_acc\", mode=\"max\")\n",
    "        val_checkpoint_loss = ModelCheckpoint(filename=\"min_loss-{epoch}-{step}-{val_loss:.3f}\", monitor = \"val_loss\", mode=\"min\")\n",
    "        latest_checkpoint = ModelCheckpoint(filename=\"latest-{epoch}-{step}\", monitor = \"step\", mode=\"max\",every_n_train_steps = 500,save_top_k = 1)\n",
    "        batchsizefinder = BatchSizeFinder(mode='power', steps_per_trial=3, init_val=2, max_trials=25, batch_arg_name='batch_size')\n",
    "        lr_finder = FineTuneLearningRateFinder(milestones=(5,10))\n",
    "        \n",
    "        torch.manual_seed(SEED)\n",
    "        print(SEED)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        output = generate_output()\n",
    "        # my data        \n",
    "        \n",
    "        train_size = int(0.8 * len(output))\n",
    "        Temp_size = len(output) - train_size\n",
    "        val_size = int(0.2*Temp_size)\n",
    "        test_size = Temp_size - val_size\n",
    "        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(output, [train_size, val_size, test_size])\n",
    "                \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        # mode\n",
    "        if classif == \"graph\":\n",
    "            model = GINE().double()#.to(device) #GINE is for graph classification\n",
    "        elif classif == \"node\":\n",
    "            model = Net().double()#.to(device) #net is for node classification\n",
    "            \n",
    "        #training\n",
    "        logger = TensorBoardLogger(save_file, name=name_of_save) # where the model saves the callbacks\n",
    "        val_check_interval=len(train_loader)\n",
    "        bar = LitProgressBar()\n",
    "        \n",
    "        trainer = pl.Trainer(logger=logger,max_epochs = range_epoch, callbacks=[val_checkpoint_best_loss, val_checkpoint_best_acc, latest_checkpoint, val_checkpoint_acc,val_checkpoint_loss,early_stop],accelerator='gpu',devices=1)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "#------------------------------------------------------------\n",
    "\n",
    "\n",
    "#main parametrs\n",
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "#paths\n",
    "path_main = \"dataset_100_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "# params for \n",
    "monitor_test = \"best_acc.ckpt\"\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 500 #set length of epoch\n",
    "save_file=\"tb_logs\"\n",
    "name_of_save = \"100\"\n",
    "#-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c85c0-2072-47a3-9118-978470089691",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1da32-0d28-44ed-995c-392aeafa373c",
   "metadata": {},
   "source": [
    "**EPOCH**  \n",
    "MTF == 0  \n",
    "VG == 1000  \n",
    "\n",
    "MTF_on_VG == 2000  \n",
    "VG_on_MTF == 3000  \n",
    "\n",
    "graph == 0  \n",
    "node == 100  \n",
    "\n",
    "uncut == 0  \n",
    "random == 10  \n",
    "\n",
    "50 == 20  \n",
    "100 == 30  \n",
    "150 == 40  \n",
    "200 == 50  \n",
    "250 == 60  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bea199-fce0-4135-a6ed-de7e721f2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"random\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_rss.npz\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"test\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 10+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e96d2-2e89-4180-ac57-17a9ef5339d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"node\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_uncut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_node_classification\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1100+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7ae67-4fed-4dc1-911f-dbe4468a0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"node\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_uncut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_node_classification\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(5): \n",
    "    SEED = 100+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b6a6a-0ff6-47d9-95ba-7a87754ec35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node classification on un/cut time series using visual_on_MTF graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | conv1 | GATConv | 512   \n",
      "1 | lin1  | Linear  | 256   \n",
      "2 | conv2 | GATConv | 16.8 K\n",
      "3 | lin2  | Linear  | 16.5 K\n",
      "4 | conv3 | GATConv | 781   \n",
      "5 | lin3  | Linear  | 129   \n",
      "----------------------------------\n",
      "35.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "35.0 K    Total params\n",
      "0.140     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978d746a4b314578aa34c9672af5e7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_type = \"visual_on_MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"node\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_uncut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_on_MTF_node_classification\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 3100+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a5a1e-c065-4e3d-b4f8-67f208f93738",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF_on_visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"node\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_uncut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "path_properties = \"dataset_properties.npz\"  # path to properties used for random \n",
    "path_mask = \"dataset_mask.npz\" # path to mask dataset used for random\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_on_VG_node_classification\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 2100+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67de62e-988e-4ddd-9fd7-97d31f7725e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609448b-a4c5-480b-a5b3-b6891ab44f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_50_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_50\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1020+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecceea73-5dfc-4411-8516-261a0b672163",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_100_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_100\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1030+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96448a3a-d101-44d0-98ae-b7f55cd37e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_150_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_150\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1040+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb54512-aa53-4839-ba76-2ede0ad8216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_200_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_200\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1050+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b16960-0a3c-436c-8f01-e27d16c21a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"visual\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_250_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"VG_250\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 1060+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf8da3-7778-4d04-8282-ba31f1c11c85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ca64e-03c4-4764-9809-2cb5eb077ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_50_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_50\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 20+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8ec34-5ccf-4cef-9167-95f69b707377",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_100_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_100\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 30+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695992ba-7510-4bb7-bcc5-3fae9450ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_150_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_150\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 40+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b91bf2-c680-4615-8266-dfde58770963",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_200_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_200\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 50+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e53567-5995-4823-ad17-cd2fa6ebb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"un/cut\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "\n",
    "path_main = \"dataset_250_cut.csv\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64*2\n",
    "range_epoch = 1000 #set length of epoch\n",
    "save_file=\"Models\"\n",
    "name_of_save = \"MTF_250\"\n",
    "patience = 200\n",
    "analysis = True\n",
    "#-------------------------------------------------------------\n",
    "for i in range(6): \n",
    "    SEED = 60+i\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e43e7-2526-43b8-a5a4-bda0d5982714",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ee351-e101-430b-baa9-ba55d5ea29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node anomaly location\n",
    "def anomaly_location_in_words():\n",
    "    my_model=my_model12\n",
    "    mm1 = []\n",
    "    mm2 = []\n",
    "    points = 0\n",
    "    if any(my_model) == 1:\n",
    "\n",
    "        my_model1 = my_model.reshape(150, -1)\n",
    "        for i in my_model1:\n",
    "            mm1 = np.append(mm1,all(i))\n",
    "        if any(mm1) == 1:\n",
    "            if my_model[-1] != 0:\n",
    "                my_model2 = my_model.reshape(2, -1)\n",
    "                for i in my_model2:\n",
    "                    mm2 = np.append(mm2,all(i))\n",
    "                if any(mm2) == 1:\n",
    "                    print(\"SlowD\")\n",
    "                    return\n",
    "                print(\"SuddenD\")\n",
    "                return\n",
    "            print(\"SuddenR\")\n",
    "            return\n",
    "        print(\"InstaD\")\n",
    "        return\n",
    "    print(\"No_anomaly\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e549935-ef2c-4ecc-afa6-0013f39150ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"MTF_random\"\n",
    "monitor_test = \"best_acc.ckpt\"\n",
    "graph_type = \"MTF\" #\"visual\", \"MTF\", \"MTF_on_visual\", \"visual_on_MTF\", graph topology\n",
    "classif = \"graph\" #\"graph\", \"node\", set the type of classification\n",
    "len_type = \"random\" #\"un/cut\", \"random\", the shape of data used in later paths \n",
    "path_main = \"dataset_rss.npz\" #\"dataset_uncut.csv\", \"dataset_cut.csv\", \"dataset_rss.npz\", paths used for cut/uncut/random dataset\n",
    "SEED = 10\n",
    "\n",
    "my_test_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
